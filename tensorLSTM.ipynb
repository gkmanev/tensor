{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series.drop_duplicates(subset='created', inplace=True)\n",
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series['created'] = pd.to_datetime(series['created'])\n",
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series['Week sin'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
      "C:\\Users\\Georgi Manev\\AppData\\Local\\Temp\\ipykernel_1736\\3371592681.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  series['Week cos'] = np.cos(timestamp_s * (2 * np.pi / week))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from tensorflow.keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.dates as mdates\n",
    "import requests\n",
    "## timestamp dependencies\n",
    "from datetime import datetime\n",
    "\n",
    "## visualisation dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# series = pd.read_csv('data.csv')\n",
    "\n",
    "url = 'http://209.38.208.230:8000/api/posts/?date_range=year&dev=sm-0006'\n",
    "response=requests.get(url).json()\n",
    "df1=pd.DataFrame(response)\n",
    "\n",
    "\n",
    "\n",
    "series = df1[['created', 'value']]\n",
    "\n",
    "series.drop_duplicates(subset='created', inplace=True)\n",
    "series['created'] = pd.to_datetime(series['created'])\n",
    "\n",
    "date_time = pd.to_datetime(series.pop('created'), format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "week = day*7\n",
    "series['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "series['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "series['Week sin'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
    "series['Week cos'] = np.cos(timestamp_s * (2 * np.pi / week))\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(series.columns)}\n",
    "\n",
    "n = len(series)\n",
    "train_df = series[0:int(n*0.7)]\n",
    "val_df = series[int(n*0.7):int(n*0.9)]\n",
    "test_df = series[int(n*0.9):]\n",
    "\n",
    "num_features = series.shape[1]\n",
    "\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "\n",
    "\n",
    "df_std = (series - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    \n",
    "  @property\n",
    "  def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "  @property\n",
    "  def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "  @property\n",
    "  def test(self):\n",
    "    return self.make_dataset(self.test_df)\n",
    "\n",
    "  @property\n",
    "  def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "      # No example batch was found, so get one from the `.train` dataset\n",
    "      result = next(iter(self.train))\n",
    "      # And cache it for next time\n",
    "      self._example = result\n",
    "    return result\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "  \n",
    "  def split_window(self, features):\n",
    "      inputs = features[:, self.input_slice, :]\n",
    "      labels = features[:, self.labels_slice, :]\n",
    "      if self.label_columns is not None:\n",
    "          labels = tf.stack(\n",
    "              [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "              axis=-1\n",
    "          )\n",
    "      inputs.set_shape([None, self.input_width, None])\n",
    "      labels.set_shape([None, self.label_width, None])\n",
    "      return inputs, labels\n",
    "  \n",
    "  def make_dataset(self, data):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=self.total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=True,\n",
    "        batch_size=32,)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "\n",
    "    return ds \n",
    "\n",
    "  def plot(self, model=None, plot_col='value', max_subplots=3):\n",
    "      inputs, labels = self.example\n",
    "      plt.figure(figsize=(12, 8))\n",
    "      plot_col_index = self.column_indices[plot_col]\n",
    "      max_n = min(max_subplots, len(inputs))\n",
    "      x = self.train_df.index  # Assuming the index represents the date and time\n",
    "\n",
    "      for n in range(max_n):\n",
    "          plt.subplot(max_n, 1, n+1)\n",
    "          plt.ylabel(f'{plot_col} [normed]')\n",
    "          plt.plot(x[self.input_indices], inputs[n, :, plot_col_index],\n",
    "                  label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "          if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "          else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "          if label_col_index is not None:\n",
    "              plt.scatter(x[self.label_indices], labels[n, :, label_col_index],\n",
    "                          edgecolors='k', label='Actual', c='#2ca02c', s=64)\n",
    "\n",
    "          if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              prediction_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "              if prediction_col_index is not None:\n",
    "                  plt.scatter(x[self.label_indices], predictions[n, :, prediction_col_index],\n",
    "                              marker='X', edgecolors='k', label='Predictions',\n",
    "                              c='#ff7f0e', s=64)\n",
    "\n",
    "          if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "      plt.xlabel('Date and Time')\n",
    "      plt.xticks(rotation=45)\n",
    "      plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 50\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=168, label_width=168, shift=1,\n",
    "    label_columns=['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m compile_and_fit(lstm_model, wide_window)\n",
      "Cell \u001b[1;32mIn[107], line 12\u001b[0m, in \u001b[0;36mcompile_and_fit\u001b[1;34m(model, window, patience)\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                                   patience\u001b[39m=\u001b[39mpatience,\n\u001b[0;32m      6\u001b[0m                                                   mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError(),\n\u001b[0;32m      9\u001b[0m               optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[0;32m     10\u001b[0m               metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanAbsoluteError()])\n\u001b[1;32m---> 12\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(window\u001b[39m.\u001b[39;49mtrain, epochs\u001b[39m=\u001b[39mMAX_EPOCHS,\n\u001b[0;32m     13\u001b[0m                     validation_data\u001b[39m=\u001b[39mwindow\u001b[39m.\u001b[39mval,\n\u001b[0;32m     14\u001b[0m                     callbacks\u001b[39m=\u001b[39m[early_stopping])\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "Cell \u001b[1;32mIn[106], line 34\u001b[0m, in \u001b[0;36mWindowGenerator.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_df)\n",
      "Cell \u001b[1;32mIn[106], line 76\u001b[0m, in \u001b[0;36mWindowGenerator.make_dataset\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_dataset\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m     75\u001b[0m   data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m---> 76\u001b[0m   ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mtimeseries_dataset_from_array(\n\u001b[0;32m     77\u001b[0m       data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m     78\u001b[0m       targets\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     79\u001b[0m       sequence_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtotal_window_size,\n\u001b[0;32m     80\u001b[0m       sequence_stride\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     81\u001b[0m       shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     82\u001b[0m       batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,)\n\u001b[0;32m     84\u001b[0m   ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_window)\n\u001b[0;32m     86\u001b[0m   \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\Georgi Manev\\anaconda3\\lib\\site-packages\\keras\\utils\\timeseries_dataset.py:188\u001b[0m, in \u001b[0;36mtimeseries_dataset_from_array\u001b[1;34m(data, targets, sequence_length, sequence_stride, sampling_rate, batch_size, shuffle, seed, start_index, end_index)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`sampling_rate` must be higher than 0. Received: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msampling_rate=\u001b[39m\u001b[39m{\u001b[39;00msampling_rate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m sampling_rate \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    189\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`sampling_rate` must be lower than the length of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata. Received: sampling_rate=\u001b[39m\u001b[39m{\u001b[39;00msampling_rate\u001b[39m}\u001b[39;00m\u001b[39m, for data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof length \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     )\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m sequence_stride \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    194\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    195\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`sequence_stride` must be higher than 0. Received: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msequence_stride=\u001b[39m\u001b[39m{\u001b[39;00msequence_stride\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: `sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 0"
     ]
    }
   ],
   "source": [
    "history = compile_and_fit(lstm_model, wide_window)\n",
    "\n",
    "#Plot the predictions to check accuracy\n",
    "#wide_window.plot(lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = wide_window.make_dataset(test_df)\n",
    "predictions = lstm_model.predict(prediction_data)\n",
    "predictions_original = (predictions * train_std['value']) + train_mean['value']\n",
    "\n",
    "#plt.plot(predictions_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions vs train_df\n",
    "wide_window.plot(lstm_model, plot_col='value', max_subplots=1)\n",
    "\n",
    "wide_window.plot(plot_col='value', max_subplots=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
